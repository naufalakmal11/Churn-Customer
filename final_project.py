# -*- coding: utf-8 -*-
"""Final Project

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iL-EnF3LQrag9_4_AWkPg4qN87SzVHjC
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

from google.colab import drive
drive.mount('/content/drive')

product = pd.read_csv ('/content/drive/MyDrive/Final Project/product.csv', error_bad_lines=False)
trans = pd.read_csv ('/content/drive/MyDrive/Final Project/cleaned_trans.csv')
cust = pd.read_csv ('/content/drive/MyDrive/Final Project/cleaned_cust.csv')

"""##**EDA Bussiness**"""

product.head()

product.groupby('articleType')['id'].nunique().reset_index()
product.sort_values

product.info()

product.isnull().sum()

merge1 = pd.merge(cust, trans, how="left", on=["customer_id"])

product1 = product.rename(columns={"id": "product_id"})

merge1.info()

merge2 = pd.merge(merge1, product1, how="left", on=["product_id"])

merge2.info()

#Mencari Pakaian Dengan Pembelian Terbanyak by Akmal
case5 = merge2 [['articleType','payment_status','customer_id']]

case5.head()

case5 = case5[case5['payment_status']=='Success']

case5 = case5.groupby('articleType')['payment_status'].size().reset_index()
case5 = case5.sort_values(by='payment_status',ascending=False)
case5 = case5.rename(columns={"payment_status": "Total_Pembelian"})
case5.head()

case3 = merge2 [['promo_code','session_id','customer_id']]

#mencari jumlah penggunaan masing-masing jenis promo berdasarkan kode by Mush'ab
promo_rank = case3.groupby('promo_code')['session_id'].nunique().reset_index()
promo_rank = promo_rank.sort_values(by='session_id', ascending=False)
promo_rank = promo_rank.rename(columns={'session_id': "Total_Penggunaan"})
promo_rank

#mencari jumlah penggunaan masing-masing jenis promo berdasarkan kode dan gender by Mush'ab
promo_bygender = merge2.groupby(['promo_code','gender_x'])['session_id'].nunique().reset_index()
promo_bygender = promo_bygender.sort_values(by='promo_code', ascending=False)
promo_bygender = promo_bygender.rename(columns={'session_id': "Total Penggunaan"})
promo_bygender

"""##**Klasifikasi Generasi**"""

case4 = merge2[['birthdate','promo_code','customer_id']]
case4.fillna('Tanpa Promo', inplace=True)
case4['birthdate'] = pd.to_datetime(case4['birthdate']).dt.year
case4.info()

#Mencari penggunaan promo
GenZ = case4['birthdate'].between(1997, 2012, inclusive = True) 
GenZ = case4[GenZ]
GenZ.loc[(GenZ['birthdate'] >= 1997 ), 'Generation'] = 'GenZ'
GenZ.head()

Millenial = case4['birthdate'].between(1981, 1996, inclusive = True) 
Millenial = case4[Millenial]
Millenial.loc[(Millenial['birthdate'] >= 1981 ), 'Generation'] = 'Millenial'
Millenial.head()

GenX = case4['birthdate'].between(1965, 1980, inclusive = True) 
GenX = case4[GenX]
GenX.loc[(GenX['birthdate'] >= 1965 ), 'Generation'] = 'GenX'
GenX.head()

BabyBoomer = case4['birthdate'].between(1946, 1964, inclusive = True) 
BabyBoomer = case4[BabyBoomer]
BabyBoomer.loc[(BabyBoomer['birthdate'] >= 1946 ), 'Generation'] = 'BabyBoomer'
BabyBoomer.head()

PostGenZ = case4['birthdate'].between(2012, 2022, inclusive = True) 
PostGenZ = case4[PostGenZ]
PostGenZ.loc[(PostGenZ['birthdate'] >= 2012 ), 'Generation'] = 'PostGenZ'
PostGenZ.head()

Generation = pd.concat([Millenial, GenZ, GenX, PostGenZ, BabyBoomer])
Generation = Generation.groupby('Generation')['promo_code'].size().reset_index()
Generation = Generation.sort_values(by='promo_code', ascending=False)
Generation = Generation.rename(columns={'promo_code': 'Total Penggunaan'})
Generation

plt.bar(Generation['Generation'], Generation['Total Penggunaan'], color ='maroon',
        width = 0.4)
 
plt.xlabel("Tital Penggunaan")
plt.ylabel("Generation")
plt.title("Pengguna Promo Terbanyak")
plt.show()

case7 = merge2[['payment_method','session_id']]
case7.head()

#Mencari peringkat metode pembayaran by Mush'ab
pay_method = case7.groupby('payment_method')['session_id'].nunique().reset_index()
pay_method = pay_method.sort_values(by='session_id', ascending=False)
pay_method = pay_method.rename(columns={'session_id': 'Total Penggunaan'})
pay_method

"""##**Churn User per Year**"""

trans2 = pd.read_csv('/content/drive/MyDrive/Final Project/transactions.csv')

trans2.head()

trans2['created_at'] = trans2['created_at'].astype(str)

trans2['created_at'] = pd.to_datetime(trans2['created_at']).dt.year
trans2.head()

success= trans2[(trans2.payment_status == 'Success')]

success.info()

row_total=success.groupby(['created_at']).agg(
    total_order   =('booking_id','nunique'),
    total_customer =('customer_id','nunique'),
    total_sales   =('total_amount','sum'),
    total_promo = ('promo_amount','sum')
)
row_total

cust = pd.read_csv ('/content/drive/MyDrive/Final Project/cleaned_cust.csv')
cust.head()

cust['first_join_date'] = cust['first_join_date'].astype(str)

cust['first_join_date'] = pd.to_datetime(cust['first_join_date']).dt.year
cust.head()

#Menghitung Jumlah Customer Setiap Tahunnya
customer_join=cust.groupby(['first_join_date']).agg(
    total_customer =('customer_id','nunique'),
)
customer_join

plt.plot(customer_join["total_customer"], marker='o')
plt.xlabel("Tahun")
plt.ylabel("Total Customer")
plt.title("Total Customer per Tahun")

churn_peryear = trans2[['created_at',
                             'customer_id',
                             'payment_status'
                           ]]
churn_peryear.head()

churn_peryear['created_at']= churn_peryear['created_at'].astype('string')

tahun_2016= churn_peryear[(churn_peryear.created_at == '2016') & (churn_peryear.payment_status == 'Success')]
tahun_2017= churn_peryear[(churn_peryear.created_at == '2017') & (churn_peryear.payment_status == 'Success')]
tahun_2018= churn_peryear[(churn_peryear.created_at == '2018') & (churn_peryear.payment_status == 'Success')]
tahun_2019= churn_peryear[(churn_peryear.created_at == '2019') & (churn_peryear.payment_status == 'Success')]
tahun_2020= churn_peryear[(churn_peryear.created_at == '2020') & (churn_peryear.payment_status == 'Success')]
tahun_2021= churn_peryear[(churn_peryear.created_at == '2021') & (churn_peryear.payment_status == 'Success')]
tahun_2022= churn_peryear[(churn_peryear.created_at == '2022') & (churn_peryear.payment_status == 'Success')]

#Menghitung Jumlah Churn User
churn_calculation = tahun_2016.merge(tahun_2018, on='customer_id', how='inner')
churn_calculation.head()

jumlah_customer_belanja_lagi=churn_calculation.customer_id.nunique()
jumlah_customer_belanja_lagi

#jumlah Warna Pada Toko
color = merge2.groupby(['baseColour','articleType'])['product_id'].size().reset_index()
color = color.sort_values(by='product_id', ascending=False)
color = color.rename(columns={'product_id': "Jumlah Product"})
color.head(10)

trans3 = pd.read_csv('/content/drive/MyDrive/Final Project/transactions.csv')
cust2 = pd.read_csv ('/content/drive/MyDrive/Final Project/cleaned_cust.csv')

merge3 = pd.merge(trans3, cust2, how="left", on=["customer_id"])
merge3.info()

"""##**Churn User Setiap Bulan**"""

#Identifikasi Churn User By Akmal & Mush'ab
case8 = trans3 [['created_at','customer_id','payment_status']]
case8 = case8[case8['payment_status']=='Success']
case8['created_at'] = case8['created_at'].astype(str)
case8['Year'] = pd.to_datetime(case8['created_at']).dt.year
case8['Month'] = pd.to_datetime(case8['created_at']).dt.month
case8

icu = case8.groupby(['Year','Month','customer_id'])['payment_status'].count().reset_index()
icu = icu.rename(columns={'payemnt_status': "pembelian"})
icu

#Tahun Pertama
jun2016 = icu[(icu.Year == 2016) & (icu.Month == 6)]
jul2016 = icu[(icu.Year == 2016) & (icu.Month == 7)]
aug2016 = icu[(icu.Year == 2016) & (icu.Month == 8)]
sep2016 = icu[(icu.Year == 2016) & (icu.Month == 9)]
oct2016 = icu[(icu.Year == 2016) & (icu.Month == 10)]
nov2016 = icu[(icu.Year == 2016) & (icu.Month == 11)]
des2016 = icu[(icu.Year == 2016) & (icu.Month == 12)]
jan2017 = icu[(icu.Year == 2017) & (icu.Month == 1)]
feb2017 = icu[(icu.Year == 2017) & (icu.Month == 2)]
mar2017 = icu[(icu.Year == 2017) & (icu.Month == 3)]
apr2017 = icu[(icu.Year == 2017) & (icu.Month == 4)]
mei2017 = icu[(icu.Year == 2017) & (icu.Month == 5)]

churn_calc1 = jun2016.merge(jul2016, on='customer_id', how='outer')
churn_calc1.fillna(0, inplace=True)
churn_calc1.loc[(churn_calc1['Year_x'] == 0) | (churn_calc1['Year_y'] == 0), 'churn'] = 1
churn_calc1.loc[(churn_calc1['Year_x'] !=0) & (churn_calc1['Year_y'] != 0), 'churn'] = 0
churn_calc1.head()

churn_calc2 = jul2016.merge(aug2016, on='customer_id', how='outer')
churn_calc2.fillna(0, inplace=True)
churn_calc2.loc[(churn_calc2['Year_x'] == 0) | (churn_calc2['Year_y'] == 0), 'churn'] = 1
churn_calc2.loc[(churn_calc2['Year_x'] !=0) & (churn_calc2['Year_y'] != 0), 'churn'] = 0
churn_calc2.head()

churn_calc3 = aug2016.merge(sep2016, on='customer_id', how='outer')
churn_calc3.fillna(0, inplace=True)
churn_calc3.loc[(churn_calc3['Year_x'] == 0) | (churn_calc3['Year_y'] == 0), 'churn'] = 1
churn_calc3.loc[(churn_calc3['Year_x'] !=0) & (churn_calc3['Year_y'] != 0), 'churn'] = 0
churn_calc3.head()

churn_calc4 = sep2016.merge(oct2016, on='customer_id', how='outer')
churn_calc4.fillna(0, inplace=True)
churn_calc4.loc[(churn_calc4['Year_x'] == 0) | (churn_calc4['Year_y'] == 0), 'churn'] = 1
churn_calc4.loc[(churn_calc4['Year_x'] !=0) & (churn_calc4['Year_y'] != 0), 'churn'] = 0
churn_calc4.head()

churn_calc5 = oct2016.merge(nov2016, on='customer_id', how='outer')
churn_calc5.fillna(0, inplace=True)
churn_calc5.loc[(churn_calc5['Year_x'] == 0) | (churn_calc5['Year_y'] == 0), 'churn'] = 1
churn_calc5.loc[(churn_calc5['Year_x'] !=0) & (churn_calc5['Year_y'] != 0), 'churn'] = 0
churn_calc5.head()

churn_calc6 = nov2016.merge(des2016, on='customer_id', how='outer')
churn_calc6.fillna(0, inplace=True)
churn_calc6.loc[(churn_calc6['Year_x'] == 0) | (churn_calc6['Year_y'] == 0), 'churn'] = 1
churn_calc6.loc[(churn_calc6['Year_x'] !=0) & (churn_calc6['Year_y'] != 0), 'churn'] = 0
churn_calc6.head()

churn_calc7 = des2016.merge(jan2017, on='customer_id', how='outer')
churn_calc7.fillna(0, inplace=True)
churn_calc7.loc[(churn_calc7['Year_x'] == 0) | (churn_calc7['Year_y'] == 0), 'churn'] = 1
churn_calc7.loc[(churn_calc7['Year_x'] !=0) & (churn_calc7['Year_y'] != 0), 'churn'] = 0
churn_calc7.head()

churn_calc8 = jan2017.merge(feb2017, on='customer_id', how='outer')
churn_calc8.fillna(0, inplace=True)
churn_calc8.loc[(churn_calc8['Year_x'] == 0) | (churn_calc8['Year_y'] == 0), 'churn'] = 1
churn_calc8.loc[(churn_calc8['Year_x'] !=0) & (churn_calc8['Year_y'] != 0), 'churn'] = 0
churn_calc8.head()

churn_calc9 = feb2017.merge(mar2017, on='customer_id', how='outer')
churn_calc9.fillna(0, inplace=True)
churn_calc9.loc[(churn_calc9['Year_x'] == 0) | (churn_calc9['Year_y'] == 0), 'churn'] = 1
churn_calc9.loc[(churn_calc9['Year_x'] !=0) & (churn_calc9['Year_y'] != 0), 'churn'] = 0
churn_calc9.head()

churn_calc10 = mar2017.merge(apr2017, on='customer_id', how='outer')
churn_calc10.fillna(0, inplace=True)
churn_calc10.loc[(churn_calc10['Year_x'] == 0) | (churn_calc10['Year_y'] == 0), 'churn'] = 1
churn_calc10.loc[(churn_calc10['Year_x'] !=0) & (churn_calc10['Year_y'] != 0), 'churn'] = 0
churn_calc10.head()

churn_calc11 = apr2017.merge(mei2017, on='customer_id', how='outer')
churn_calc11.fillna(0, inplace=True)
churn_calc11.loc[(churn_calc11['Year_x'] == 0) | (churn_calc11['Year_y'] == 0), 'churn'] = 1
churn_calc11.loc[(churn_calc11['Year_x'] !=0) & (churn_calc11['Year_y'] != 0), 'churn'] = 0
churn_calc11.head()

tahun_pertama = pd.concat([churn_calc1, churn_calc2, churn_calc3, churn_calc4, churn_calc5, 
                          churn_calc6, churn_calc7, churn_calc8, churn_calc9, churn_calc10,
                          churn_calc11])
tahun_pertama.info()

#Tahun Kedua
jun2017 = icu[(icu.Year == 2017) & (icu.Month == 6)]
jul2017 = icu[(icu.Year == 2017) & (icu.Month == 7)]
aug2017 = icu[(icu.Year == 2017) & (icu.Month == 8)]
sep2017 = icu[(icu.Year == 2017) & (icu.Month == 9)]
oct2017 = icu[(icu.Year == 2017) & (icu.Month == 10)]
nov2017 = icu[(icu.Year == 2017) & (icu.Month == 11)]
des2017 = icu[(icu.Year == 2017) & (icu.Month == 12)]
jan2018 = icu[(icu.Year == 2018) & (icu.Month == 1)]
feb2018 = icu[(icu.Year == 2018) & (icu.Month == 2)]
mar2018 = icu[(icu.Year == 2018) & (icu.Month == 3)]
apr2018 = icu[(icu.Year == 2018) & (icu.Month == 4)]
mei2018 = icu[(icu.Year == 2018) & (icu.Month == 5)]

churn_calc12 = mei2017.merge(jun2017, on='customer_id', how='outer')
churn_calc12.fillna(0, inplace=True)
churn_calc12.loc[(churn_calc12['Year_x'] == 0) | (churn_calc12['Year_y'] == 0), 'churn'] = 1
churn_calc12.loc[(churn_calc12['Year_x'] !=0) & (churn_calc12['Year_y'] != 0), 'churn'] = 0
churn_calc12.head()

churn_calc13 = jun2017.merge(jul2017, on='customer_id', how='outer')
churn_calc13.fillna(0, inplace=True)
churn_calc13.loc[(churn_calc13['Year_x'] == 0) | (churn_calc13['Year_y'] == 0), 'churn'] = 1
churn_calc13.loc[(churn_calc13['Year_x'] !=0) & (churn_calc13['Year_y'] != 0), 'churn'] = 0
churn_calc13.head()

churn_calc14 = jul2017.merge(aug2017, on='customer_id', how='outer')
churn_calc14.fillna(0, inplace=True)
churn_calc14.loc[(churn_calc14['Year_x'] == 0) | (churn_calc14['Year_y'] == 0), 'churn'] = 1
churn_calc14.loc[(churn_calc14['Year_x'] !=0) & (churn_calc14['Year_y'] != 0), 'churn'] = 0
churn_calc14.head()

churn_calc15 = aug2017.merge(sep2017, on='customer_id', how='outer')
churn_calc15.fillna(0, inplace=True)
churn_calc15.loc[(churn_calc15['Year_x'] == 0) | (churn_calc15['Year_y'] == 0), 'churn'] = 1
churn_calc15.loc[(churn_calc15['Year_x'] !=0) & (churn_calc15['Year_y'] != 0), 'churn'] = 0
churn_calc15.head()

churn_calc16 = sep2017.merge(oct2017, on='customer_id', how='outer')
churn_calc16.fillna(0, inplace=True)
churn_calc16.loc[(churn_calc16['Year_x'] == 0) | (churn_calc16['Year_y'] == 0), 'churn'] = 1
churn_calc16.loc[(churn_calc16['Year_x'] !=0) & (churn_calc16['Year_y'] != 0), 'churn'] = 0
churn_calc16.head()

churn_calc17 = oct2017.merge(nov2017, on='customer_id', how='outer')
churn_calc17.fillna(0, inplace=True)
churn_calc17.loc[(churn_calc17['Year_x'] == 0) | (churn_calc17['Year_y'] == 0), 'churn'] = 1
churn_calc17.loc[(churn_calc17['Year_x'] !=0) & (churn_calc17['Year_y'] != 0), 'churn'] = 0
churn_calc17.head()

churn_calc18 = nov2017.merge(des2017, on='customer_id', how='outer')
churn_calc18.fillna(0, inplace=True)
churn_calc18.loc[(churn_calc18['Year_x'] == 0) | (churn_calc18['Year_y'] == 0), 'churn'] = 1
churn_calc18.loc[(churn_calc18['Year_x'] !=0) & (churn_calc18['Year_y'] != 0), 'churn'] = 0
churn_calc18.head()

churn_calc19 = des2017.merge(jan2018, on='customer_id', how='outer')
churn_calc19.fillna(0, inplace=True)
churn_calc19.loc[(churn_calc19['Year_x'] == 0) | (churn_calc19['Year_y'] == 0), 'churn'] = 1
churn_calc19.loc[(churn_calc19['Year_x'] !=0) & (churn_calc19['Year_y'] != 0), 'churn'] = 0
churn_calc19.head()

churn_calc20 = jan2018.merge(feb2018, on='customer_id', how='outer')
churn_calc20.fillna(0, inplace=True)
churn_calc20.loc[(churn_calc20['Year_x'] == 0) | (churn_calc20['Year_y'] == 0), 'churn'] = 1
churn_calc20.loc[(churn_calc20['Year_x'] !=0) & (churn_calc20['Year_y'] != 0), 'churn'] = 0
churn_calc20.head()

churn_calc21 = feb2018.merge(mar2018, on='customer_id', how='outer')
churn_calc21.fillna(0, inplace=True)
churn_calc21.loc[(churn_calc21['Year_x'] == 0) | (churn_calc21['Year_y'] == 0), 'churn'] = 1
churn_calc21.loc[(churn_calc21['Year_x'] !=0) & (churn_calc21['Year_y'] != 0), 'churn'] = 0
churn_calc21.head()

churn_calc22 = mar2018.merge(apr2018, on='customer_id', how='outer')
churn_calc22.fillna(0, inplace=True)
churn_calc22.loc[(churn_calc22['Year_x'] == 0) | (churn_calc22['Year_y'] == 0), 'churn'] = 1
churn_calc22.loc[(churn_calc22['Year_x'] !=0) & (churn_calc22['Year_y'] != 0), 'churn'] = 0
churn_calc22.head()

churn_calc23 = apr2018.merge(mei2018, on='customer_id', how='outer')
churn_calc23.fillna(0, inplace=True)
churn_calc23.loc[(churn_calc23['Year_x'] == 0) | (churn_calc23['Year_y'] == 0), 'churn'] = 1
churn_calc23.loc[(churn_calc23['Year_x'] !=0) & (churn_calc23['Year_y'] != 0), 'churn'] = 0
churn_calc23.head()

tahun_kedua = pd.concat([churn_calc12, churn_calc13, churn_calc14, churn_calc15, churn_calc16, 
                          churn_calc17, churn_calc18, churn_calc19, churn_calc20, churn_calc21,
                          churn_calc22, churn_calc23])
tahun_kedua.info()

#Tahun Ketiga
jun2018 = icu[(icu.Year == 2018) & (icu.Month == 6)]
jul2018 = icu[(icu.Year == 2018) & (icu.Month == 7)]
aug2018 = icu[(icu.Year == 2018) & (icu.Month == 8)]
sep2018 = icu[(icu.Year == 2018) & (icu.Month == 9)]
oct2018 = icu[(icu.Year == 2018) & (icu.Month == 10)]
nov2018 = icu[(icu.Year == 2018) & (icu.Month == 11)]
des2018 = icu[(icu.Year == 2018) & (icu.Month == 12)]
jan2019 = icu[(icu.Year == 2019) & (icu.Month == 1)]
feb2019 = icu[(icu.Year == 2019) & (icu.Month == 2)]
mar2019 = icu[(icu.Year == 2019) & (icu.Month == 3)]
apr2019 = icu[(icu.Year == 2019) & (icu.Month == 4)]
mei2019 = icu[(icu.Year == 2019) & (icu.Month == 5)]

churn_calc24 = mei2018.merge(jun2018, on='customer_id', how='outer')
churn_calc24.fillna(0, inplace=True)
churn_calc24.loc[(churn_calc24['Year_x'] == 0) | (churn_calc24['Year_y'] == 0), 'churn'] = 1
churn_calc24.loc[(churn_calc24['Year_x'] !=0) & (churn_calc24['Year_y'] != 0), 'churn'] = 0
churn_calc24.head()

churn_calc25 = jun2018.merge(jul2018, on='customer_id', how='outer')
churn_calc25.fillna(0, inplace=True)
churn_calc25.loc[(churn_calc25['Year_x'] == 0) | (churn_calc25['Year_y'] == 0), 'churn'] = 1
churn_calc25.loc[(churn_calc25['Year_x'] !=0) & (churn_calc25['Year_y'] != 0), 'churn'] = 0
churn_calc25.head()

churn_calc26 = jul2018.merge(aug2018, on='customer_id', how='outer')
churn_calc26.fillna(0, inplace=True)
churn_calc26.loc[(churn_calc26['Year_x'] == 0) | (churn_calc26['Year_y'] == 0), 'churn'] = 1
churn_calc26.loc[(churn_calc26['Year_x'] !=0) & (churn_calc26['Year_y'] != 0), 'churn'] = 0
churn_calc26.head()

churn_calc27 = aug2018.merge(sep2018, on='customer_id', how='outer')
churn_calc27.fillna(0, inplace=True)
churn_calc27.loc[(churn_calc27['Year_x'] == 0) | (churn_calc27['Year_y'] == 0), 'churn'] = 1
churn_calc27.loc[(churn_calc27['Year_x'] !=0) & (churn_calc27['Year_y'] != 0), 'churn'] = 0
churn_calc27.head()

churn_calc28 = sep2018.merge(oct2018, on='customer_id', how='outer')
churn_calc28.fillna(0, inplace=True)
churn_calc28.loc[(churn_calc28['Year_x'] == 0) | (churn_calc28['Year_y'] == 0), 'churn'] = 1
churn_calc28.loc[(churn_calc28['Year_x'] !=0) & (churn_calc28['Year_y'] != 0), 'churn'] = 0
churn_calc28.head()

churn_calc29 = oct2018.merge(nov2018, on='customer_id', how='outer')
churn_calc29.fillna(0, inplace=True)
churn_calc29.loc[(churn_calc29['Year_x'] == 0) | (churn_calc29['Year_y'] == 0), 'churn'] = 1
churn_calc29.loc[(churn_calc29['Year_x'] !=0) & (churn_calc29['Year_y'] != 0), 'churn'] = 0
churn_calc29.head()

churn_calc30 = nov2018.merge(des2018, on='customer_id', how='outer')
churn_calc30.fillna(0, inplace=True)
churn_calc30.loc[(churn_calc30['Year_x'] == 0) | (churn_calc30['Year_y'] == 0), 'churn'] = 1
churn_calc30.loc[(churn_calc30['Year_x'] !=0) & (churn_calc30['Year_y'] != 0), 'churn'] = 0
churn_calc30.head()

churn_calc31 = des2018.merge(jan2019, on='customer_id', how='outer')
churn_calc31.fillna(0, inplace=True)
churn_calc31.loc[(churn_calc31['Year_x'] == 0) | (churn_calc31['Year_y'] == 0), 'churn'] = 1
churn_calc31.loc[(churn_calc31['Year_x'] !=0) & (churn_calc31['Year_y'] != 0), 'churn'] = 0
churn_calc31.head()

churn_calc32 = jan2019.merge(feb2019, on='customer_id', how='outer')
churn_calc32.fillna(0, inplace=True)
churn_calc32.loc[(churn_calc32['Year_x'] == 0) | (churn_calc32['Year_y'] == 0), 'churn'] = 1
churn_calc32.loc[(churn_calc32['Year_x'] !=0) & (churn_calc32['Year_y'] != 0), 'churn'] = 0
churn_calc32.head()

churn_calc33 = feb2019.merge(mar2019, on='customer_id', how='outer')
churn_calc33.fillna(0, inplace=True)
churn_calc33.loc[(churn_calc33['Year_x'] == 0) | (churn_calc33['Year_y'] == 0), 'churn'] = 1
churn_calc33.loc[(churn_calc33['Year_x'] !=0) & (churn_calc33['Year_y'] != 0), 'churn'] = 0
churn_calc33.head()

churn_calc34 = mar2019.merge(apr2019, on='customer_id', how='outer')
churn_calc34.fillna(0, inplace=True)
churn_calc34.loc[(churn_calc34['Year_x'] == 0) | (churn_calc34['Year_y'] == 0), 'churn'] = 1
churn_calc34.loc[(churn_calc34['Year_x'] !=0) & (churn_calc34['Year_y'] != 0), 'churn'] = 0
churn_calc34.head()

churn_calc35 = apr2019.merge(mei2019, on='customer_id', how='outer')
churn_calc35.fillna(0, inplace=True)
churn_calc35.loc[(churn_calc35['Year_x'] == 0) | (churn_calc35['Year_y'] == 0), 'churn'] = 1
churn_calc35.loc[(churn_calc35['Year_x'] !=0) & (churn_calc35['Year_y'] != 0), 'churn'] = 0
churn_calc35.head()

tahun_ketiga = pd.concat([churn_calc24, churn_calc25, churn_calc26, churn_calc27, churn_calc28, 
                          churn_calc29, churn_calc30, churn_calc31, churn_calc32, churn_calc33,
                          churn_calc34, churn_calc35])
tahun_ketiga.info()

#Tahun Keempat
jun2019 = icu[(icu.Year == 2019) & (icu.Month == 6)]
jul2019 = icu[(icu.Year == 2019) & (icu.Month == 7)]
aug2019 = icu[(icu.Year == 2019) & (icu.Month == 8)]
sep2019 = icu[(icu.Year == 2019) & (icu.Month == 9)]
oct2019 = icu[(icu.Year == 2019) & (icu.Month == 10)]
nov2019 = icu[(icu.Year == 2019) & (icu.Month == 11)]
des2019 = icu[(icu.Year == 2019) & (icu.Month == 12)]
jan2020 = icu[(icu.Year == 2020) & (icu.Month == 1)]
feb2020 = icu[(icu.Year == 2020) & (icu.Month == 2)]
mar2020 = icu[(icu.Year == 2020) & (icu.Month == 3)]
apr2020 = icu[(icu.Year == 2020) & (icu.Month == 4)]
mei2020 = icu[(icu.Year == 2020) & (icu.Month == 5)]

churn_calc36 = mei2019.merge(jun2019, on='customer_id', how='outer')
churn_calc36.fillna(0, inplace=True)
churn_calc36.loc[(churn_calc36['Year_x'] == 0) | (churn_calc36['Year_y'] == 0), 'churn'] = 1
churn_calc36.loc[(churn_calc36['Year_x'] !=0) & (churn_calc36['Year_y'] != 0), 'churn'] = 0
churn_calc36.head()

churn_calc37 = jun2019.merge(jul2019, on='customer_id', how='outer')
churn_calc37.fillna(0, inplace=True)
churn_calc37.loc[(churn_calc37['Year_x'] == 0) | (churn_calc37['Year_y'] == 0), 'churn'] = 1
churn_calc37.loc[(churn_calc37['Year_x'] !=0) & (churn_calc37['Year_y'] != 0), 'churn'] = 0
churn_calc37.head()

churn_calc38 = jul2019.merge(aug2019, on='customer_id', how='outer')
churn_calc38.fillna(0, inplace=True)
churn_calc38.loc[(churn_calc38['Year_x'] == 0) | (churn_calc38['Year_y'] == 0), 'churn'] = 1
churn_calc38.loc[(churn_calc38['Year_x'] !=0) & (churn_calc38['Year_y'] != 0), 'churn'] = 0
churn_calc38.head()

churn_calc39 = aug2019.merge(sep2019, on='customer_id', how='outer')
churn_calc39.fillna(0, inplace=True)
churn_calc39.loc[(churn_calc39['Year_x'] == 0) | (churn_calc39['Year_y'] == 0), 'churn'] = 1
churn_calc39.loc[(churn_calc39['Year_x'] !=0) & (churn_calc39['Year_y'] != 0), 'churn'] = 0
churn_calc39.head()

churn_calc40 = sep2019.merge(oct2019, on='customer_id', how='outer')
churn_calc40.fillna(0, inplace=True)
churn_calc40.loc[(churn_calc40['Year_x'] == 0) | (churn_calc40['Year_y'] == 0), 'churn'] = 1
churn_calc40.loc[(churn_calc40['Year_x'] !=0) & (churn_calc40['Year_y'] != 0), 'churn'] = 0
churn_calc40.head()

churn_calc41 = oct2019.merge(nov2019, on='customer_id', how='outer')
churn_calc41.fillna(0, inplace=True)
churn_calc41.loc[(churn_calc41['Year_x'] == 0) | (churn_calc41['Year_y'] == 0), 'churn'] = 1
churn_calc41.loc[(churn_calc41['Year_x'] !=0) & (churn_calc41['Year_y'] != 0), 'churn'] = 0
churn_calc41.head()

churn_calc42 = nov2019.merge(des2019, on='customer_id', how='outer')
churn_calc42.fillna(0, inplace=True)
churn_calc42.loc[(churn_calc42['Year_x'] == 0) | (churn_calc42['Year_y'] == 0), 'churn'] = 1
churn_calc42.loc[(churn_calc42['Year_x'] !=0) & (churn_calc42['Year_y'] != 0), 'churn'] = 0
churn_calc42.head()

churn_calc43 = des2019.merge(jan2020, on='customer_id', how='outer')
churn_calc43.fillna(0, inplace=True)
churn_calc43.loc[(churn_calc43['Year_x'] == 0) | (churn_calc43['Year_y'] == 0), 'churn'] = 1
churn_calc43.loc[(churn_calc43['Year_x'] !=0) & (churn_calc43['Year_y'] != 0), 'churn'] = 0
churn_calc43.head()

churn_calc44 = jan2020.merge(feb2020, on='customer_id', how='outer')
churn_calc44.fillna(0, inplace=True)
churn_calc44.loc[(churn_calc44['Year_x'] == 0) | (churn_calc44['Year_y'] == 0), 'churn'] = 1
churn_calc44.loc[(churn_calc44['Year_x'] !=0) & (churn_calc44['Year_y'] != 0), 'churn'] = 0
churn_calc44.head()

churn_calc45 = feb2020.merge(mar2020, on='customer_id', how='outer')
churn_calc45.fillna(0, inplace=True)
churn_calc45.loc[(churn_calc45['Year_x'] == 0) | (churn_calc45['Year_y'] == 0), 'churn'] = 1
churn_calc45.loc[(churn_calc45['Year_x'] !=0) & (churn_calc45['Year_y'] != 0), 'churn'] = 0
churn_calc45.head()

churn_calc46 = mar2020.merge(apr2020, on='customer_id', how='outer')
churn_calc46.fillna(0, inplace=True)
churn_calc46.loc[(churn_calc46['Year_x'] == 0) | (churn_calc46['Year_y'] == 0), 'churn'] = 1
churn_calc46.loc[(churn_calc46['Year_x'] !=0) & (churn_calc46['Year_y'] != 0), 'churn'] = 0
churn_calc46.head()

churn_calc47 = apr2020.merge(mei2020, on='customer_id', how='outer')
churn_calc47.fillna(0, inplace=True)
churn_calc47.loc[(churn_calc47['Year_x'] == 0) | (churn_calc47['Year_y'] == 0), 'churn'] = 1
churn_calc47.loc[(churn_calc47['Year_x'] !=0) & (churn_calc47['Year_y'] != 0), 'churn'] = 0
churn_calc47.head()

tahun_keempat = pd.concat([churn_calc36, churn_calc37, churn_calc38, churn_calc39, churn_calc40, 
                          churn_calc41, churn_calc42, churn_calc43, churn_calc44, churn_calc45,
                          churn_calc46, churn_calc47])
tahun_keempat.info()

#Tahun Kelima
jun2020 = icu[(icu.Year == 2020) & (icu.Month == 6)]
jul2020 = icu[(icu.Year == 2020) & (icu.Month == 7)]
aug2020 = icu[(icu.Year == 2020) & (icu.Month == 8)]
sep2020 = icu[(icu.Year == 2020) & (icu.Month == 9)]
oct2020 = icu[(icu.Year == 2020) & (icu.Month == 10)]
nov2020 = icu[(icu.Year == 2020) & (icu.Month == 11)]
des2020 = icu[(icu.Year == 2020) & (icu.Month == 12)]
jan2021 = icu[(icu.Year == 2021) & (icu.Month == 1)]
feb2021 = icu[(icu.Year == 2021) & (icu.Month == 2)]
mar2021 = icu[(icu.Year == 2021) & (icu.Month == 3)]
apr2021 = icu[(icu.Year == 2021) & (icu.Month == 4)]
#mei2021 = icu[(icu.Year == 2021) & (icu.Month == 5)] Tidak ada data di bulan mei 2021

churn_calc48 = mei2020.merge(jun2020, on='customer_id', how='outer')
churn_calc48.fillna(0, inplace=True)
churn_calc48.loc[(churn_calc48['Year_x'] == 0) | (churn_calc48['Year_y'] == 0), 'churn'] = 1
churn_calc48.loc[(churn_calc48['Year_x'] !=0) & (churn_calc48['Year_y'] != 0), 'churn'] = 0
churn_calc48.head()

churn_calc49 = jun2020.merge(jul2020, on='customer_id', how='outer')
churn_calc49.fillna(0, inplace=True)
churn_calc49.loc[(churn_calc49['Year_x'] == 0) | (churn_calc49['Year_y'] == 0), 'churn'] = 1
churn_calc49.loc[(churn_calc49['Year_x'] !=0) & (churn_calc49['Year_y'] != 0), 'churn'] = 0
churn_calc49.head()

churn_calc50 = jul2020.merge(aug2020, on='customer_id', how='outer')
churn_calc50.fillna(0, inplace=True)
churn_calc50.loc[(churn_calc50['Year_x'] == 0) | (churn_calc50['Year_y'] == 0), 'churn'] = 1
churn_calc50.loc[(churn_calc50['Year_x'] !=0) & (churn_calc50['Year_y'] != 0), 'churn'] = 0
churn_calc50.head()

churn_calc51 = aug2020.merge(sep2020, on='customer_id', how='outer')
churn_calc51.fillna(0, inplace=True)
churn_calc51.loc[(churn_calc51['Year_x'] == 0) | (churn_calc51['Year_y'] == 0), 'churn'] = 1
churn_calc51.loc[(churn_calc51['Year_x'] !=0) & (churn_calc51['Year_y'] != 0), 'churn'] = 0
churn_calc51.head()

churn_calc52 = sep2020.merge(oct2020, on='customer_id', how='outer')
churn_calc52.fillna(0, inplace=True)
churn_calc52.loc[(churn_calc52['Year_x'] == 0) | (churn_calc52['Year_y'] == 0), 'churn'] = 1
churn_calc52.loc[(churn_calc52['Year_x'] !=0) & (churn_calc52['Year_y'] != 0), 'churn'] = 0
churn_calc52.head()

churn_calc53 = oct2020.merge(nov2020, on='customer_id', how='outer')
churn_calc53.fillna(0, inplace=True)
churn_calc53.loc[(churn_calc53['Year_x'] == 0) | (churn_calc53['Year_y'] == 0), 'churn'] = 1
churn_calc53.loc[(churn_calc53['Year_x'] !=0) & (churn_calc53['Year_y'] != 0), 'churn'] = 0
churn_calc53.head()

churn_calc54 = nov2020.merge(des2020, on='customer_id', how='outer')
churn_calc54.fillna(0, inplace=True)
churn_calc54.loc[(churn_calc54['Year_x'] == 0) | (churn_calc54['Year_y'] == 0), 'churn'] = 1
churn_calc54.loc[(churn_calc54['Year_x'] !=0) & (churn_calc54['Year_y'] != 0), 'churn'] = 0
churn_calc54.head()

churn_calc55 = des2020.merge(jan2021, on='customer_id', how='outer')
churn_calc55.fillna(0, inplace=True)
churn_calc55.loc[(churn_calc55['Year_x'] == 0) | (churn_calc55['Year_y'] == 0), 'churn'] = 1
churn_calc55.loc[(churn_calc55['Year_x'] !=0) & (churn_calc55['Year_y'] != 0), 'churn'] = 0
churn_calc55.head()

churn_calc56 = jan2021.merge(feb2021, on='customer_id', how='outer')
churn_calc56.fillna(0, inplace=True)
churn_calc56.loc[(churn_calc56['Year_x'] == 0) | (churn_calc56['Year_y'] == 0), 'churn'] = 1
churn_calc56.loc[(churn_calc56['Year_x'] !=0) & (churn_calc56['Year_y'] != 0), 'churn'] = 0
churn_calc56.head()

churn_calc57 = feb2021.merge(mar2021, on='customer_id', how='outer')
churn_calc57.fillna(0, inplace=True)
churn_calc57.loc[(churn_calc57['Year_x'] == 0) | (churn_calc57['Year_y'] == 0), 'churn'] = 1
churn_calc57.loc[(churn_calc57['Year_x'] !=0) & (churn_calc57['Year_y'] != 0), 'churn'] = 0
churn_calc57.head()

churn_calc58 = mar2021.merge(apr2021, on='customer_id', how='outer')
churn_calc58.fillna(0, inplace=True)
churn_calc58.loc[(churn_calc58['Year_x'] == 0) | (churn_calc58['Year_y'] == 0), 'churn'] = 1
churn_calc58.loc[(churn_calc58['Year_x'] !=0) & (churn_calc58['Year_y'] != 0), 'churn'] = 0
churn_calc58.head()

tahun_kelima = pd.concat([churn_calc48, churn_calc49, churn_calc50, churn_calc51, churn_calc52, 
                          churn_calc53, churn_calc54, churn_calc55, churn_calc56, churn_calc57,
                          churn_calc58])
tahun_kelima.info()

#Tahun Keenam
jun2021 = icu[(icu.Year == 2021) & (icu.Month == 6)]
jul2021 = icu[(icu.Year == 2021) & (icu.Month == 7)]
aug2021 = icu[(icu.Year == 2021) & (icu.Month == 8)]
sep2021 = icu[(icu.Year == 2021) & (icu.Month == 9)]
oct2021 = icu[(icu.Year == 2021) & (icu.Month == 10)]
nov2021 = icu[(icu.Year == 2021) & (icu.Month == 11)]
des2021 = icu[(icu.Year == 2021) & (icu.Month == 12)]
jan2022 = icu[(icu.Year == 2022) & (icu.Month == 1)]
feb2022 = icu[(icu.Year == 2022) & (icu.Month == 2)]
mar2022 = icu[(icu.Year == 2022) & (icu.Month == 3)]
apr2022 = icu[(icu.Year == 2022) & (icu.Month == 4)]
#mei2022 = icu[(icu.Year == 2022) & (icu.Month == 5)] Tidak ada data bulan mei 2022
jun2022 = icu[(icu.Year == 2022) & (icu.Month == 6)]
jul2022 = icu[(icu.Year == 2022) & (icu.Month == 7)]

churn_calc59 = apr2021.merge(jun2021, on='customer_id', how='outer')
churn_calc59.fillna(0, inplace=True)
churn_calc59.loc[(churn_calc59['Year_x'] == 0) | (churn_calc59['Year_y'] == 0), 'churn'] = 1
churn_calc59.loc[(churn_calc59['Year_x'] !=0) & (churn_calc59['Year_y'] != 0), 'churn'] = 0
churn_calc59.head()

churn_calc61 = jun2021.merge(jul2021, on='customer_id', how='outer')
churn_calc61.fillna(0, inplace=True)
churn_calc61.loc[(churn_calc61['Year_x'] == 0) | (churn_calc61['Year_y'] == 0), 'churn'] = 1
churn_calc61.loc[(churn_calc61['Year_x'] !=0) & (churn_calc61['Year_y'] != 0), 'churn'] = 0
churn_calc61.head()

churn_calc62 = jul2021.merge(aug2021, on='customer_id', how='outer')
churn_calc62.fillna(0, inplace=True)
churn_calc62.loc[(churn_calc62['Year_x'] == 0) | (churn_calc62['Year_y'] == 0), 'churn'] = 1
churn_calc62.loc[(churn_calc62['Year_x'] !=0) & (churn_calc62['Year_y'] != 0), 'churn'] = 0
churn_calc62.head()

churn_calc63 = aug2021.merge(sep2021, on='customer_id', how='outer')
churn_calc63.fillna(0, inplace=True)
churn_calc63.loc[(churn_calc63['Year_x'] == 0) | (churn_calc63['Year_y'] == 0), 'churn'] = 1
churn_calc63.loc[(churn_calc63['Year_x'] !=0) & (churn_calc63['Year_y'] != 0), 'churn'] = 0
churn_calc63.head()

churn_calc64 = sep2021.merge(oct2021, on='customer_id', how='outer')
churn_calc64.fillna(0, inplace=True)
churn_calc64.loc[(churn_calc64['Year_x'] == 0) | (churn_calc64['Year_y'] == 0), 'churn'] = 1
churn_calc64.loc[(churn_calc64['Year_x'] !=0) & (churn_calc64['Year_y'] != 0), 'churn'] = 0
churn_calc64.head()

churn_calc65 = oct2021.merge(nov2021, on='customer_id', how='outer')
churn_calc65.fillna(0, inplace=True)
churn_calc65.loc[(churn_calc65['Year_x'] == 0) | (churn_calc65['Year_y'] == 0), 'churn'] = 1
churn_calc65.loc[(churn_calc65['Year_x'] !=0) & (churn_calc65['Year_y'] != 0), 'churn'] = 0
churn_calc65.head()

churn_calc66 = nov2021.merge(des2021, on='customer_id', how='outer')
churn_calc66.fillna(0, inplace=True)
churn_calc66.loc[(churn_calc66['Year_x'] == 0) | (churn_calc66['Year_y'] == 0), 'churn'] = 1
churn_calc66.loc[(churn_calc66['Year_x'] !=0) & (churn_calc66['Year_y'] != 0), 'churn'] = 0
churn_calc66.head()

churn_calc67 = des2021.merge(jan2022, on='customer_id', how='outer')
churn_calc67.fillna(0, inplace=True)
churn_calc67.loc[(churn_calc67['Year_x'] == 0) | (churn_calc67['Year_y'] == 0), 'churn'] = 1
churn_calc67.loc[(churn_calc67['Year_x'] !=0) & (churn_calc67['Year_y'] != 0), 'churn'] = 0
churn_calc67.head()

churn_calc68 = jan2022.merge(feb2022, on='customer_id', how='outer')
churn_calc68.fillna(0, inplace=True)
churn_calc68.loc[(churn_calc68['Year_x'] == 0) | (churn_calc68['Year_y'] == 0), 'churn'] = 1
churn_calc68.loc[(churn_calc68['Year_x'] !=0) & (churn_calc68['Year_y'] != 0), 'churn'] = 0
churn_calc68.head()

churn_calc69 = feb2022.merge(mar2022, on='customer_id', how='outer')
churn_calc69.fillna(0, inplace=True)
churn_calc69.loc[(churn_calc69['Year_x'] == 0) | (churn_calc69['Year_y'] == 0), 'churn'] = 1
churn_calc69.loc[(churn_calc69['Year_x'] !=0) & (churn_calc69['Year_y'] != 0), 'churn'] = 0
churn_calc69.head()

churn_calc70 = mar2022.merge(apr2022, on='customer_id', how='outer')
churn_calc70.fillna(0, inplace=True)
churn_calc70.loc[(churn_calc70['Year_x'] == 0) | (churn_calc70['Year_y'] == 0), 'churn'] = 1
churn_calc70.loc[(churn_calc70['Year_x'] !=0) & (churn_calc70['Year_y'] != 0), 'churn'] = 0
churn_calc70.head()

churn_calc71 = apr2022.merge(jun2022, on='customer_id', how='outer')
churn_calc71.fillna(0, inplace=True)
churn_calc71.loc[(churn_calc71['Year_x'] == 0) | (churn_calc71['Year_y'] == 0), 'churn'] = 1
churn_calc71.loc[(churn_calc71['Year_x'] !=0) & (churn_calc71['Year_y'] != 0), 'churn'] = 0
churn_calc71.head()

churn_calc73 = jun2022.merge(jul2022, on='customer_id', how='outer')
churn_calc73.fillna(0, inplace=True)
churn_calc73.loc[(churn_calc73['Year_x'] == 0) | (churn_calc73['Year_y'] == 0), 'churn'] = 1
churn_calc73.loc[(churn_calc73['Year_x'] !=0) & (churn_calc73['Year_y'] != 0), 'churn'] = 0
churn_calc73.head()

tahun_keenam = pd.concat([churn_calc59, churn_calc61, churn_calc62, churn_calc63, churn_calc64, 
                          churn_calc65, churn_calc66, churn_calc67, churn_calc68, churn_calc69,
                          churn_calc70, churn_calc71, churn_calc73])
tahun_keenam.info()

churn_user = pd.concat([tahun_pertama, tahun_kedua, tahun_ketiga, tahun_keempat, tahun_kelima, tahun_keenam])
churn_user = churn_user.drop(columns=['payment_status_x', 'payment_status_y'])
churn_user.head()

#Hubungan Generasi dengan churn by Akmal
Generation = pd.concat([Millenial, GenZ, GenX, PostGenZ, BabyBoomer])
churn_generation = churn_user.merge(Generation, on='customer_id', how='left')

churn_generation.head()

churn_gen = churn_generation.groupby(['Generation','churn'])['customer_id'].count().reset_index()
churn_gen

#Hubungan Churn dengan Promo
churn_pr = churn_generation.groupby(['promo_code','churn'])['customer_id'].count().reset_index()
churn_pr

churn_user1 = churn_user.groupby(['Year_x','churn'])['customer_id'].count().reset_index()
churn_user1 = churn_user1.rename(columns={'customer_id' : 'Total'})
churn_user1

"""##**Feature Engineering**"""

feature_eng1 = trans3.merge(cust2, on='customer_id', how='left')
spender_segmentation = feature_eng1[["created_at", "customer_id", "first_name", "last_name" ,"total_amount","first_join_date"]]
spender_segmentation.head()

spender_segmentation["Name"] = spender_segmentation['first_name'].astype(str) +" "+ spender_segmentation["last_name"]
second_step = spender_segmentation[['customer_id',
                          'Name',
                          'first_join_date',
                          'created_at'
                        ]]
second_step

second_step['created_at'] = pd.to_datetime(second_step['created_at']).dt.date
second_step

second_step['created_at'] =  pd.to_datetime(second_step['created_at'], format='%Y-%m-%d')
second_step['first_join_date'] =  pd.to_datetime(second_step['first_join_date'], format='%Y-%m-%d')

third_step=second_step[second_step.groupby('customer_id').first_join_date.transform('max') == second_step.first_join_date]
third_step

fourth_step=third_step[second_step.groupby('customer_id').created_at.transform('max') == third_step.created_at]
fourth_step

final_customer_transaction=fourth_step
final_customer_transaction

sales_data_join = trans3[['customer_id','booking_id','total_amount']]
sales_data_join

sales_dataset=sales_data_join.merge(final_customer_transaction, on='customer_id', how='inner')
sales_dataset.info()

bahan_segment_satu=sales_dataset.groupby(['customer_id','Name','first_join_date','created_at']).agg(
    total_order   =('booking_id','nunique'),
    total_sales   =('total_amount','sum')
)
bahan_segment_satu.sort_values(by="total_sales", ascending=False)

bahan_segment_satu['basket_size']= bahan_segment_satu['total_sales'] / bahan_segment_satu['total_order']
bahan_segment_satu

segmentation_raw = bahan_segment_satu.astype({"basket_size":'int'})
segmentation_raw

##Second Segmentation
segmentation_raw.loc[(segmentation_raw['basket_size'] < 300000), 'monetary_segementation'] = 'Low Spender'
segmentation_raw.loc[(segmentation_raw['basket_size']>=300000) & (segmentation_raw['basket_size']<=1000000), 'monetary_segementation'] = 'Normal'
segmentation_raw.loc[(segmentation_raw['basket_size']>1000000) & (segmentation_raw['basket_size']<=3000000), 'monetary_segementation'] = 'Silver'
segmentation_raw.loc[(segmentation_raw['basket_size']>3000000) & (segmentation_raw['basket_size']<=10000000), 'monetary_segementation'] = 'Gold'
segmentation_raw.loc[(segmentation_raw['basket_size']> 10000000), 'monetary_segementation'] = 'Platinum'
segmentation_raw.sort_values(by="created_at", ascending=False)

segment_second=segmentation_raw.reset_index()
segment_second

segment_second['date_state'] = pd.Timestamp('2022-07-31')
segment_second

segment_state = segment_second
segment_state['date_state'] = pd.to_datetime(segment_state['date_state'], format='%Y-%m-%d')
segment_state.head()

import numpy as np
segment_state['beda_bulan'] = (segment_state['date_state'] - segment_state['created_at']) / np.timedelta64(1, 'M')
segment_state

segmentation_fixing = segment_state.astype({"beda_bulan":'int'}) 
segmentation_fixing

segmentation_fixing.loc[(segmentation_fixing['total_order']>=1)&(segmentation_fixing['beda_bulan']>12), 'first_segmentation'] = 'Inactive'
segmentation_fixing.loc[(segmentation_fixing['total_order']>1)&(segmentation_fixing['beda_bulan']>=6)&(segmentation_fixing['beda_bulan']<=12),'first_segmentation'] = 'Defecting'
segmentation_fixing.loc[(segmentation_fixing['total_order']>1)&(segmentation_fixing['beda_bulan']<6), 'first_segmentation'] = 'Active'
segmentation_fixing.loc[(segmentation_fixing['total_order']==1)&(segmentation_fixing['beda_bulan']<6), 'first_segmentation'] = 'First Timer'
segmentation_fixing

##Churn Segmentation
segmentation_fixing.loc[(segmentation_fixing['created_at'] < '2022-07-01'), 'churn_segmentation'] = 'Churn'
segmentation_fixing

##Fix Churn Segmentation
segmentation_fixing.loc[(segmentation_fixing['churn_segmentation'] == 'Churn'), 'segementation_churn'] = 'Churn Customer'
segmentation_fixing.loc[(segmentation_fixing['churn_segmentation'] != 'Churn'), 'segementation_churn'] = 'Non-Churn Customer'
segmentation_fixing

segment_fix = segmentation_fixing[['customer_id',
                                          'Name',
                                          'total_order',
                                          'total_sales',
                                          'basket_size',
                                          'monetary_segementation',
                                          'first_segmentation',
                                          'segementation_churn']]
segment_fix

trial=segment_fix.groupby(['monetary_segementation','first_segmentation','segementation_churn'])['customer_id'].nunique().reset_index()
trial

"""##**Feature Correlation**"""

import seaborn as sns

features_check = segment_fix.drop(['customer_id', 'Name'], axis=1)
features_check.head()

plt.figure(figsize=(12,10))
sns.heatmap(features_check.corr())

"""##**Logistic Regression**"""

# Commented out IPython magic to ensure Python compatibility.
#Logistic Regression By Akmal
from sklearn.model_selection import train_test_split
import seaborn as sb
from sklearn.linear_model import LogisticRegression
# %matplotlib inline
from sklearn import preprocessing

label_encoder = preprocessing.LabelEncoder()

segment_fix['monetary_segementation'] = label_encoder.fit_transform(segment_fix['monetary_segementation'])
segment_fix['monetary_segementation'].unique()

segment_fix['first_segmentation'] = label_encoder.fit_transform(segment_fix['first_segmentation'])
segment_fix['first_segmentation'].unique()

segment_fix['segementation_churn'] = label_encoder.fit_transform(segment_fix['segementation_churn'])
segment_fix['segementation_churn'].unique()

x = segment_fix[['monetary_segementation', 'first_segmentation', 'total_order', 'basket_size', 'total_sales']]
y = segment_fix['segementation_churn']

X_train, X_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=10)

clf = LogisticRegression()

clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)

clf.score(X_test, y_test)

from sklearn.metrics import classification_report
print(classification_report(y_pred, y_test))

from sklearn.metrics import confusion_matrix
confusion_matrix(y_test, y_pred)

from sklearn.utils.multiclass import unique_labels
unique_labels(y_test)

def plot(y_train, y_pred):
  labels = unique_labels(y_test)
  column = [f'Predicted{label}' for label in labels]
  indices = [f'Actual{label}' for label in labels]
  table = pd.DataFrame(confusion_matrix(y_train, y_pred),
                       columns=column, index=indices)
  
  return table

import seaborn as sns
def plot2(y_train, y_pred):
  labels = unique_labels(y_test)
  column = [f'Predicted{label}' for label in labels]
  indices = [f'Actual{label}' for label in labels]
  table = pd.DataFrame(confusion_matrix(y_train, y_pred),
                       columns=column, index=indices)
  
  return sns.heatmap(table, annot=True, fmt='d', cmap='viridis')

plot2(y_test, y_pred)

"""##**Decision Tree**"""

#Decision Tree By Mushab
from sklearn.tree import DecisionTreeClassifier

X = segment_fix[['monetary_segementation', 'first_segmentation','basket_size', 'total_sales', 'total_order']]
y = segment_fix['segementation_churn']

X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=10)


# Fit Regression Model
regr = DecisionTreeClassifier(max_depth=2)
regr.fit(X_train, y_train)

# Predict
y_pred_dt = regr.predict(X_test)
regr.score(X_test, y_test)

from sklearn.metrics import classification_report
print(classification_report(y_pred_dt, y_test))

import seaborn as sns
def plot3(y_train, y_pred_dt):
  labels = unique_labels(y_test)
  column = [f'Predicted{label}' for label in labels]
  indices = [f'Actual{label}' for label in labels]
  table = pd.DataFrame(confusion_matrix(y_train, y_pred_dt),
                       columns=column, index=indices)
    
  return sns.heatmap(table, annot=True, fmt='d', cmap='viridis')

plot3(y_test, y_pred)

"""## **Random Forest**"""

#Decision Tree By Mushab
from sklearn.ensemble import RandomForestClassifier

X = segment_fix[['monetary_segementation', 'first_segmentation','basket_size', 'total_sales', 'total_order']]
y = segment_fix['segementation_churn']

X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=10)


# Fit Regression Model
rfc = RandomForestClassifier(max_depth=2)
rfc.fit(X_train, y_train)

# Predict
y_pred_dt = rfc.predict(X_test)
rfc.score(X_test, y_test)

"""##**Hyperparameter Tuning**

###Logistic Regression
"""

#By Mushab dan Akmal
#Logistic Regression
# Build the steps
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.model_selection import GridSearchCV
steps = [("scaler", StandardScaler()),
         ("logreg", LogisticRegression())]
pipeline = Pipeline(steps)

# Create the parameter space
parameters = {"logreg__C": np.linspace(0.001, 1.0, 20),
              "logreg__class_weight": [dict, 'balanced'],
              "logreg__penalty": ['l1', 'l2', 'elasticnet', 'none']}
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, 
                                                    random_state=21)

# Instantiate the grid search object
cv = GridSearchCV(pipeline, param_grid=parameters)

# Fit to the training data
cv.fit(X_train, y_train)
print(cv.best_score_, "\n", cv.best_params_)

# Create the parameter space
parameters = {"logreg__solver": ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],
              "logreg__warm_start": [True, False],
              "logreg__fit_intercept": [True, False],
              "logreg__dual": [True, False]}
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, 
                                                    random_state=21)

# Instantiate the grid search object
cv = GridSearchCV(pipeline, param_grid=parameters)

# Fit to the training data
cv.fit(X_train, y_train)
print(cv.best_score_, "\n", cv.best_params_)

model_new = LogisticRegression(C = 0.47421052631578947, class_weight = dict, penalty = 'l2', 
                               dual = False, fit_intercept = True, solver = 'saga', 
                               warm_start = False)
model_new.fit(X_train, y_train)
model_new.predict(X_test)
model_new.score(X_test, y_test)

"""###Decision Tree"""

#By Mushab & Akmal
# DecisionTree
# Build the steps
steps = [("scaler", StandardScaler()),
         ("dt", DecisionTreeClassifier())]
pipeline = Pipeline(steps)

# Create the parameter space
paramdt2 = {
    'dt__max_depth': [2, 3, 5, 10, 20],
    'dt__min_samples_leaf': [5, 10, 20, 50, 100],
    'dt__criterion': ["gini", "entropy"]
}

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, 
                                                    random_state=21)

# Instantiate the grid search object
cv = GridSearchCV(pipeline, param_grid=paramdt2)

# Fit to the training data
cv.fit(X_train, y_train)
print(cv.best_score_, "\n", cv.best_params_)

# Decision Tree Param2 
# Create the parameter space
paramdt2 = {
    'dt__splitter': ["best", "random"],
    'dt__min_samples_split': [5, 10, 20, 50, 100],
    'dt__class_weight': [dict, "balanced"]
}

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, 
                                                    random_state=21)

# Instantiate the grid search object
cv = GridSearchCV(pipeline, param_grid=paramdt2)

# Fit to the training data
cv.fit(X_train, y_train)
print(cv.best_score_, "\n", cv.best_params_)

# Decision Tree Params 3
# Create the parameter space
paramdt3 = {
    'dt__max_features': ["auto", "sqrt", "log2"],
    'dt__min_weight_fraction_leaf': np.arange(0, 0.5),
  
}

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, 
                                                    random_state=21)

# Instantiate the grid search object
cv = GridSearchCV(pipeline, param_grid=paramdt3)

# Fit to the training data
cv.fit(X_train, y_train)
print(cv.best_score_, "\n", cv.best_params_)

model_new2 = DecisionTreeClassifier(criterion = 'gini', max_depth = 5, min_samples_leaf = 20)
model_new2.fit(X_train, y_train)
model_new2.predict(X_test)
model_new2.score(X_test, y_test)

"""###Random Forest"""

# By Mushab dan Akmal
# Random Forest
# Build the steps
steps = [("scaler", StandardScaler()),
         ("rfc", RandomForestClassifier())]
pipeline = Pipeline(steps)

# Create the parameter space
params1 = {
    'rfc__max_depth': [2, 3, 5, 10, 20],
    'rfc__min_samples_leaf': [5, 10, 20, 50, 100],
    'rfc__criterion': ["gini", "entropy"]
}

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, 
                                                    random_state=21)

# Instantiate the grid search object
cv = GridSearchCV(pipeline, param_grid=params1)

# Fit to the training data
cv.fit(X_train, y_train)
print(cv.best_score_, "\n", cv.best_params_)

# Create the parameter space
params1 = {
    'rfc__max_features': ["sqrt", "log2", "auto", None],
    'rfc__bootstrap': [True, False],
    'rfc__oob_score': [True, False]
}

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, 
                                                    random_state=21)

# Instantiate the grid search object
cv = GridSearchCV(pipeline, param_grid=params1)

# Fit to the training data
cv.fit(X_train, y_train)
print(cv.best_score_, "\n", cv.best_params_)

# Create the parameter space
params1 = {
    'rfc__warm_start': [True, False],
    'rfc__class_weight': ["balanced", "balanced_subsample"]
}

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, 
                                                    random_state=21)

# Instantiate the grid search object
cv = GridSearchCV(pipeline, param_grid=params1)

# Fit to the training data
cv.fit(X_train, y_train)
print(cv.best_score_, "\n", cv.best_params_)

model_new3 = RandomForestClassifier(criterion = 'entropy', max_depth = 10, min_samples_leaf = 50)
model_new3.fit(X_train, y_train)
model_new3.predict(X_test)
model_new3.score(X_test, y_test)

import seaborn as sns
def plot4(y_train, X_test):
  labels = unique_labels(y_test)
  column = [f'Predicted{label}' for label in labels]
  indices = [f'Actual{label}' for label in labels]
  table = pd.DataFrame(confusion_matrix(y_train, X_test),
                       columns=column, index=indices)
    
  return sns.heatmap(table, annot=True, fmt='d', cmap='viridis')

plot4(y_test, y_pred)

from sklearn import model_selection
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import RandomizedSearchCV
from sklearn.model_selection import ShuffleSplit
from sklearn.model_selection import KFold

"""##**ROC Curve & AOC**"""

# Instantiate the best model after hyperparameter tuning
rf = RandomForestClassifier(criterion = 'entropy', max_depth = 10, min_samples_leaf = 50)

# Fit the model
rf.fit(X_train, y_train)

# Predict probabilities
y_pred_probs = rf.predict_proba(X_test)[:, 1]

print(y_pred_probs[:10])

# Import roc_curve
from sklearn.metrics import roc_curve

# Generate ROC curve values: fpr, tpr, thresholds
fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs)

plt.plot([0, 1], [0, 1], 'k--')

# Plot tpr against fpr
plt.plot(fpr, tpr)
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve for Churn Prediction')
plt.show()

# Import roc_auc_score
from sklearn.metrics import roc_auc_score

# Calculate roc_auc_score
print(roc_auc_score(y_test, y_pred_probs))

# Calculate the confusion matrix
print(confusion_matrix(y_test, y_pred))

# Calculate the classification report
print(classification_report(y_test, y_pred))

"""##**Feature Importance**"""

rf.feature_importances_

penting = pd.DataFrame({'feature':X_train.columns, 'coef':rf.feature_importances_})

penting.sort_values(by='coef').sort_values(by='coef', ascending=False)

plt.figure(figsize=(12,10))
sns.barplot(data=penting.sort_values(by='coef', ascending=False), y="feature", x="coef")

"""##**Prediction**"""

from sklearn.feature_selection import RFE
rfe = RFE(rf, step = 15)
rfe = rfe.fit(X, y)

# Getting the predicted values on the full dataset
y_train_pred = rf.predict(X)
y_train_pred[:10]

rfe.support_

list(zip(X.columns, rfe.support_, rfe.ranking_))

# col = X_train.columns[rfe.support_]
col = X.columns
X.columns[~rfe.support_]

import statsmodels.api as sm

X_sm = sm.add_constant(X[col])
logm2 = sm.GLM(y,X_sm, family = sm.families.Binomial())
res = logm2.fit()
res.summary()

# Getting the predicted values on the train set
y_full_pred = res.predict(X_sm)
y_full_pred[:10]

y_full_pred = y_full_pred.values.reshape(-1)
y_full_pred[:10]

y_full_pred_final = pd.DataFrame({'Churn':y.values, 'Churn_Prob':y_full_pred})
y_full_pred_final['customer_id'] = segmentation_fixing['customer_id']
y_full_pred_final

y_full_pred_final['predicted'] = y_full_pred_final.Churn_Prob.map(lambda x: 1 if x > 0.3 else 0)

# Let's see the head
y_full_pred_final.head()

from sklearn import metrics

# Let's check the overall accuracy.
print(metrics.accuracy_score(y_full_pred_final.Churn, y_full_pred_final.predicted))

predictions = pd.DataFrame()
predictions['true'] = y_train
predictions['preds'] = rf.predict(X_train)

predictions_test = pd.DataFrame()
predictions_test['true'] = y_test
predictions_test['preds'] = rf.predict(X_test)

from sklearn.metrics import classification_report, accuracy_score
train_acc = accuracy_score(predictions.true, predictions.preds)
test_acc = accuracy_score(predictions_test.true, predictions_test.preds)

print(f"Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}")

print(classification_report(predictions.true, predictions.preds))

print(classification_report(predictions_test.true, predictions_test.preds))

probs = rf.predict_proba(X_test)[:, 1]
probs

from matplotlib.pyplot import figure
plt.figure(figsize=(12, 8))

plt.hist(probs, bins = int(180/6))
plt.title('Probability Distribution of Churn Risk')
plt.xlabel('Churn Risk')
plt.ylabel('# Customers')
plt.show()

"""##**Merge Prediction Table**"""

y_full_pred_final

merged_all = segmentation_fixing.merge(y_full_pred_final, on='customer_id', how='inner')
merged_all.drop('churn_segmentation', axis=1)

merged_all['segementation_churn'].value_counts()

cek_churn = merged_all.loc[(merged_all['churn_segmentation'] == "Churn") & (merged_all['Churn'] == 0)]
cek_churn

#replace labelling churn = 1
merged_all['Churn'] = merged_all['Churn'].replace({ 0 : 1, 1: 0})
merged_all

plt.hist(merged_all['Churn_Prob'], bins=10)

merged_all.info()

Generation1 = pd.concat([Millenial, GenZ, GenX, PostGenZ, BabyBoomer])
Generation1.reset_index()

Generation1.head()

result = pd.merge(merged_all, Generation1, how="left", on=["customer_id"])
result

result.info()

result.to_csv ('/content/drive/MyDrive/Final Project/result.csv')